{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FERM experiment examples with Adult and Drug datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "from datasets import *\n",
    "from learning_algorithms import *\n",
    "from fairness_metrics import fairness_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear FERM on drug dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug Consumption, Arrhythmia and German Credit datasets need to be loaded in this way. \n",
    "data_full = drug()\n",
    "data = data_full[0]\n",
    "labels = data_full[1]\n",
    "m, n = data.shape\n",
    "train_data, train_labels, test_data, test_labels = split(data, labels, m)\n",
    "train = namedtuple('_', 'data, labels')(train_data, train_labels)\n",
    "g = 5 # ethnicity (white, ethnic minority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 10\n",
    "\n",
    "acc = []\n",
    "eo = []\n",
    "eod = []\n",
    "dp = []\n",
    "te = []\n",
    "S = []\n",
    "\n",
    "for r in range(runs): # runs not required for Adult as Adult comes with train/test splits\n",
    "    \n",
    "    # new data shuffle and split each run\n",
    "    data_full = drug()\n",
    "    data = data_full[0]\n",
    "    labels = data_full[1]\n",
    "    m, n = data.shape\n",
    "    train_data, train_labels, test_data, test_labels = split(data, labels, m)\n",
    "    train = namedtuple('_', 'data, labels')(train_data, train_labels)\n",
    "    g = 5\n",
    "    \n",
    "    # train model. loss type options: HINGE, MSE, CE. fairness_transform options: DEO, DDP\n",
    "    LA = LinearAlg(loss_type='MSE', fairness_transform='DEO')\n",
    "    LA.execute(train, g)  \n",
    "    \n",
    "    # get predictions\n",
    "    train_preds = LA.predict(train_data)\n",
    "    test_preds = LA.predict(test_data)\n",
    "    \n",
    "    # get accuracy\n",
    "    acc_te = accuracy_score(test_labels, test_preds)\n",
    "    acc_tr = accuracy_score(train_labels, train_preds)\n",
    "    acc.append(acc_te)\n",
    "    \n",
    "    # get fairness scores\n",
    "    tr_s = fairness_scores(train_data, train_labels, train_preds, g)\n",
    "    train_scores = tr_s.get_scores2()\n",
    "\n",
    "    te_s = fairness_scores(test_data, test_labels, test_preds, g)\n",
    "    test_scores = te_s.get_scores2()\n",
    "\n",
    "    scores = [acc_te, test_scores[0], test_scores[1],  test_scores[2], test_scores[3]]\n",
    "    \n",
    "    S.append(scores)\n",
    "    eo.append(test_scores[0])\n",
    "    eod.append(test_scores[1])\n",
    "    dp.append(test_scores[2])\n",
    "    te.append(test_scores[3])\n",
    "    \n",
    "S = np.array(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and standard deviations of scores\n",
    "for i in range(len(S[0,:])):\n",
    "    avg = np.mean(S[:,i])\n",
    "    sd = np.std(S[:,i])\n",
    "    print('mean=', avg, 'sd=',sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear FERM on Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = adult()\n",
    "train_data = train[0]\n",
    "train_labels = train[1]\n",
    "test_data = test[0]\n",
    "test_labels = test[1]\n",
    "\n",
    "g = 9 # female or male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "gamma = 1\n",
    "C_val = 0.1\n",
    "LA = Non_LinearAlg(algorithm='FERM')\n",
    "LA.execute(train, g, gamma=gamma, C=C_val)\n",
    "\n",
    "# get predictions and accuracy\n",
    "train_preds, acc_tr = LA.predict(train_data, train_labels)\n",
    "test_preds, acc_te = LA.predict(test_data, test_labels)\n",
    "\n",
    "# get fairness scores\n",
    "tr_s = fairness_scores(train_data, train_labels, train_preds, g)\n",
    "train_scores = tr_s.get_scores()\n",
    "\n",
    "te_s = fairness_scores(test_data, test_labels, test_preds, g)\n",
    "test_scores = te_s.get_scores()\n",
    "\n",
    "scores = [acc_tr, train_scores[0], train_scores[1],  train_scores[2], train_scores[3], \n",
    "            acc_te, test_scores[0], test_scores[1],  test_scores[2], test_scores[3]]\n",
    "\n",
    "print(\"TRAINING. Accuracy: {}, Equal opportunity: {}, Equalized odds: {}, Demographic parity: {}, Treatment equality: {}\".format(scores[0], scores[1], scores[2], scores[3], scores[4]))\n",
    "print(\"TESTING. Accuracy: {}, Equal opportunity: {}, Equalized odds: {}, Demographic parity: {}, Treatment equality: {}\".format(scores[5], scores[6], scores[7], scores[8], scores[9]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
